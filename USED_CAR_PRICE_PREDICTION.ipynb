{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Blue'> Used Car Price Prediction  </span>\n",
    "\n",
    "## Problem Statement: Pandemic-Driven Purchase\n",
    "\n",
    "In the recent days, due to pandemic, many individuals are looking forward to owning a vehicle who otherwise preferred public transport.\n",
    "The fear of contacting virus while using a public transport, prompted consumers to owning ga vehicle. Considering affrordability we can observe a trend in growth of used car market.\n",
    "Second hand cars are preferred mostly by those who cannot afford to buy new cars at higher prices.\n",
    "This is a attempt to predict used car price with help of data so that customers can be offered competitive prices. \n",
    "\n",
    "### Please vote up and share your feedback in the comment box, if you like this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img src=\"https://ichef.bbci.co.uk/news/976/cpsprodpb/10316/production/_121162366_gettyimages-1233138884.jpg\" width=\"500px\"/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "Selling_Price : The price of the used car in INR Lakhs.<br>\n",
    "Name : The brand and model of the car.<br>\n",
    "Location : The location in which the car is being sold or is available for purchase.<br>\n",
    "Year : The year or edition of the model.<br>\n",
    "Kilometers Driven : The total kilometers driven in the car by the previous owner(s) in KM.<br>\n",
    "Fuel Type : The type of fuel used by the car. (Petrol, Diesel, Electric, CNG, LPG)<br>\n",
    "Transmission : The type of transmission used by the car. (Automatic / Manual)<br>\n",
    "Seller_Type : Whether the seller an Individual, Dealer or Trustmark Dealer.<br>\n",
    "Owner Type : Whether the ownership is Firsthand, Second hand or other.<br>\n",
    "Mileage : The standard mileage offered by the car company in kmpl(Petrol/Diesel) or km/kg(CNG/ LPG)<br>\n",
    "Current_Mileage : Current mileage claimed by the seller.<br>\n",
    "Engine : The displacement volume of the engine in CC.<br>\n",
    "Power : The maximum power of the engine in bhp<br>\n",
    "Seats : The number of seats in the car.<br>\n",
    "New_Price : Latest price of vehicle.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12104/4065471304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from wordcloud import WordCloud\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "class color:\n",
    "   BLUE = '\\033[94m'\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data_2.csv')\n",
    "test_data = pd.read_csv('test_data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Blue'> Data Overview  </span>\n",
    "\n",
    "Let us look at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(color.BOLD + \"There are {} rows and {} columns in the dataset.\".format(train_data.shape[0],train_data.shape[1]),\"\\n\"+ color.END)\n",
    "print(\"The first column is unnamed which seems to be the index which can be deleted and reset the index.\",\"\\n\")\n",
    "train_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(color.BOLD +color.BLUE +\"Let's look at the data types available in the dataset\"+ color.END)\n",
    "train_data.info()\n",
    "print(color.BOLD +color.BLUE +\"\\n\",\"Summary statistics of dataset\"+ color.END)\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selling Price\n",
    "selling price is given in INR Lakhs, we will multiply the columns with 1,00,000. to get the correct price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Selling_Price'] = train_data['Selling_Price'].apply(lambda x: x*100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"There are {} rows and {} columns in the dataset.\".format(test_data.shape[0],test_data.shape[1]),\"\\n\"+ color.END)\n",
    "print(\"The first column is unnamed which seems to be the index which can be deleted and reset the index.\",\"\\n\")\n",
    "test_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(color.BOLD +color.BLUE +\"Let's look at the data types available in the dataset\"+ color.END)\n",
    "test_data.info()\n",
    "print(color.BOLD +color.BLUE +\"\\n\",\"Summary statistics of dataset\"+ color.END)\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are columns such as Current_Mileage, Engine, Power, Seats and New_Price which have null-values.<br>\n",
    "Also, data type of appropriate columns have to be changed to meet the requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Converting to appropriate data type  </span>\n",
    "\n",
    "\n",
    "Though data types of Year and Seats are 'int64' and 'float64' respectively, using them with the same datatype will not be useful for our evaluation.<br>\n",
    "we need to convert these parameters into datetime and categorical(nominal) respectively.<br>\n",
    "Also, Location, Fuel_type, Transmission, Owner_Type, Seller_Type can all be changed to categorical variables.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seats Column\n",
    "There are records where Seats is given as 0 which is misleading. This can be assumed that number of seats is not recorded for those enteries. We will consider this as NaN an impute them with make and model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seats_(df):\n",
    "    df['Seats'].replace(0, np.nan, inplace=True)\n",
    "    df['Seats'] = df['Seats'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seats_(train_data)\n",
    "seats_(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year column\n",
    "we will calculate the age of vehicle from Year column and drop Year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = datetime.datetime.now().year #get current year\n",
    "def veh_age(df):\n",
    "    df[\"vehicle_age\"] = df['Year'].apply(lambda x: current_year-x)  # substract to get the year delta\n",
    "    df.drop('Year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_age(train_data)\n",
    "veh_age(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current_Mileage and Mileage\n",
    "Current_Mileage and Mileage have units which have to be removed and these should be converted into appropriate datatype 'float64'.\n",
    "When Fuel_Type is CNG/ LPG units for Current_Mileage and mileage are km/kg, when Fuel_Type is Petrol/ Diesel units are kmpl.\n",
    "In addition there are values with 'null' in the column, null can be converted to NaN and imputed later on.\n",
    "Units can be removed using regex or str operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '\\s\\D+[/]*\\D+'\n",
    "\n",
    "def mileage_(df):\n",
    "    df['Current_Mileage'] = df['Current_Mileage'].replace(to_replace = pattern, value = '', regex = True)\n",
    "    df['Current_Mileage'] = df['Current_Mileage'].astype(float)\n",
    "    df['Mileage'] = df['Mileage'].replace(to_replace = pattern, value = '', regex = True)\n",
    "    df['Mileage'] = df['Mileage'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileage_(train_data)\n",
    "mileage_(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Blue'> Feature Engineering  </span>\n",
    "\n",
    "## <span style='color:Maroon'> Missing  Value Treatment  </span>\n",
    "\n",
    "### Check for null/ nan in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checknull(df):\n",
    "    # printing column name where null is present\n",
    "    col_name = df.isnull().sum(axis=0).sort_values(ascending = False)\n",
    "    print(col_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"printing column name where null is present in train data\"+ color.END, '\\n')\n",
    "checknull(train_data)\n",
    "print(color.BOLD +\"printing column name where null is present in test data\"+ color.END, '\\n')\n",
    "checknull(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"There are many null values in New_Price. It is very difficult to impute those values. Hence we will drop that column from both test and train data.\",\"\\n\"+ color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('New_Price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop('New_Price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +'Rows with NaN in Mileage in train data',\"\\n\"+ color.END)\n",
    "train_data[train_data['Mileage'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"There are {} row entries for electric vehicle in train data.\".format(train_data['Fuel_Type'][train_data['Fuel_Type'] == 'Electric'].count()),\"\\n\"+ color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"There are {} row entries for electric vehicle in test data.\".format(test_data['Fuel_Type'][test_data['Fuel_Type'] == 'Electric'].count()),\"\\n\"+ color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For electric vehicle instead of mileage there is a parameter called range.<br>Range is Distance km/Charge.\n",
    "Also there is no Electric in fuel type in test data. To maintain uniformity these two rows can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes where Fuel_Type column has value Electric\n",
    "indexNames = train_data[train_data['Fuel_Type'] == 'Electric'].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "train_data.drop(indexNames , inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are records where Current_Mileage is given as 0 which is misleading. This can be assumed that the Current_Mileage is not recorded.\n",
    "We will consider this as NaN an replace during imputation with the mileage value given by the manufacturer.<br>\n",
    "\n",
    "## <span style='color:Maroon'> Removing suffixes from values in a column  </span>\n",
    "\n",
    "\n",
    "For Engine units are CC.<br>For Power units are bhp. In addition there are values with 'null bhp' in the column, null can be converted to NaN and imputed later on. <br>\n",
    "Units can be removed using regex or str operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '\\s\\D+[/]*\\D+'\n",
    "\n",
    "def curmil_eng_pow(df):\n",
    "    df['Current_Mileage'].replace(0, np.nan, inplace=True)\n",
    "    df['Mileage'].replace(0, np.nan, inplace=True)\n",
    "    print(\"There are {} null in Current_Mileage.Replace them with the mileage value\".format(df['Current_Mileage'].isna().sum()),\"\\n\")\n",
    "    df.Current_Mileage.fillna(df.Mileage, inplace=True)\n",
    "    \n",
    "    df['Engine'] = df['Engine'].replace(to_replace = pattern, value = '', regex = True)\n",
    "    df['Engine'] = df['Engine'].astype(\"float\").astype(\"Int64\")\n",
    "    df['Power'] = pd.to_numeric(df['Power'].str.lower().str.split().str.get(0).str.replace('null',''), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"Treating train data\"+ color.END, '\\n')\n",
    "curmil_eng_pow(train_data)\n",
    "print(color.BOLD +\"Treating test data\"+ color.END, '\\n')\n",
    "curmil_eng_pow(test_data)\n",
    "\n",
    "print(\"Remove units and change datatype for Engine and Power\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Splitting columns  </span>\n",
    "\n",
    "We can extract the Make and model infomation from name.<br>\n",
    "We can split Make and Model into separate columns which can be used further  and drop name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_make_and_model(df):\n",
    "    \n",
    "    #Get the Make from the name\n",
    "    make_list=list(df['Name'].str.lower())\n",
    "    i=0\n",
    "\n",
    "    for item in make_list:\n",
    "        make_list[i] = item.split(' ')[0]\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    # replace formated Names into Make  \n",
    "    df['Make']=make_list\n",
    "    \n",
    "    #Get the Model from the name\n",
    "    model_list=list(df['Name'].str.lower())\n",
    "    i=0\n",
    "\n",
    "    for item in model_list:\n",
    "        model_list[i] = item.split(' ')[0]+'_'+item.split(' ')[1]\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    # replace formated Names into Model  \n",
    "    df['Model']=model_list\n",
    "    \n",
    "    #Drop name column\n",
    "    df.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_make_and_model(train_data)\n",
    "get_make_and_model(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Impute missing values  </span>\n",
    "\n",
    "Impute missing values in 'Power','Mileage', 'Seats','Engine','Seller_Type'.<br>\n",
    "\n",
    "Vehicles with different variants of under same Make and Model tend to have same Engine capacity and Power.<br>\n",
    "All missing values in Engine and Power column, missing values can be imputed based on the Make and Model information available.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=  train_data.sort_values(['Make','Model'])\n",
    "for column in ['Power','Mileage', 'Seats','Engine','Seller_Type']:\n",
    "    train_data[column].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=  test_data.sort_values(['Make','Model'])\n",
    "for column in ['Power','Mileage', 'Seats','Engine','Seller_Type']:\n",
    "    test_data[column].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Checking Distribution of Numeric Variables  </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "numeric_traindf = train_data.select_dtypes(include=['int64','float']).drop(columns=['Selling_Price'])\n",
    "\n",
    "row_nums = 2  # how many rows of plots\n",
    "col_nums = 3  # how many plots per row\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(nrows=row_nums, ncols=col_nums, figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(numeric_traindf.columns):\n",
    "    sns.distplot(numeric_traindf[column],ax=axes[i//col_nums,i%col_nums])\n",
    "    #sns.histplot(numeric_traindf[column],ax=axes[i//col_nums,i%col_nums], color=\"red\", kde=True)\n",
    "\n",
    "\n",
    "    \n",
    "# \"i//ncols gives the floor division which is the row when you are working left to right then top to bottom.\n",
    "# i%ncols will give you the integer remainder which is the column when you are working left to right top to bottom.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distribution of kilometers_driven is highly positive skewed\n",
    "* Distribution of Engine, Power and vehicle_age are moderately positive skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_traindf.agg(['skew', 'kurtosis']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As rule of thumb, skewness can be interpreted like this: <br>\n",
    "\n",
    "Skewness<br>\n",
    "Fairly Symmetrical\t-0.5 to 0.5<br>\n",
    "Moderate Skewed\t-0.5 to -1.0 and 0.5 to 1.0<br>\n",
    "Highly Skewed\t< -1.0 and > 1.0<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Correlation between variables  </span>\n",
    "\n",
    "### Relation between Mileage, Engine and Power\n",
    "\n",
    "Over period, values specified by manufaturer such as Mileage, Engine and Power will eventually change due to wear and tear, hence we will drop these columns.<br>\n",
    "Also, the values are given by the manufacturer cannot be a deciding factor to buy a vehicle.<br>\n",
    "For understanding we can check the correlation with the target value(used car price).<br>\n",
    "These are the data given by the manufaturer.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Step 0 - Read the dataset, calculate column correlations and make a seaborn heatmap\n",
    "df_cor = train_data.select_dtypes(include=['int64','float']).drop(columns=['Kilometers_Driven', 'vehicle_age'])\n",
    "corr = df_cor.corr()\n",
    "print(corr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "#ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap= sns.diverging_palette(20, 220, as_cmap=True), square=True, annot=True, fmt='.1f')\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap= 'Blues', square=True, annot=True, fmt='.2f')\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45,horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* selling_Price(used car price) has a moderate correlation with Power and low correlation with the mileage.<br>\n",
    "* Engine and Power have high correlation with each other.<br>\n",
    "* Mileage and Current_Mileage have high correlation with each other.<br>\n",
    "* Based on correlation we will Drop 'Mileage','Engine' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column_list=['Mileage','Engine','Power']\n",
    "train_data.drop(drop_column_list, axis=1, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(drop_column_list, axis=1, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Outlier Treatment  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.select_dtypes(include=['int64','float']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Kilometers_Driven and vehicle_age\n",
    "\n",
    "Third Quartile and above values in Kilometers_Driven have very high values. We will look at them closely to get an understanding about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes where Fuel_Type column has value Electric\n",
    "train_data[train_data['Kilometers_Driven'] >= 300000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one entry where Kilometers_Driven is 6500000 which is not likely possible considering age of the vehicle.<br> we will replace this value by max of km driven based on age of that vehicle.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_=train_data.loc[train_data['Kilometers_Driven'] == train_data['Kilometers_Driven'].max()].index.item()\n",
    "vehicle_age_=train_data['vehicle_age'][train_data['Kilometers_Driven'] == train_data['Kilometers_Driven'].max()].item()\n",
    "\n",
    "print(color.BOLD +\"Maximum in Kilometers_Driven is {}, this is an outlier\".format(train_data['Kilometers_Driven'].max()), \"\\n\"+ color.END)\n",
    "print(color.BOLD +\"Index of this row is {} and age of this vehicle is {}\".format(index_,vehicle_age_), \"\\n\"+ color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Kilometers_Driven'] = train_data['Kilometers_Driven'].replace(train_data['Kilometers_Driven'].max(),np.NaN)\n",
    "replace_=train_data['Kilometers_Driven'].groupby(train_data['vehicle_age']).get_group(vehicle_age_).max()\n",
    "print(color.BOLD +\"Maximum Kilometers_Driven by vehicles with age of {} is {}\".format(vehicle_age_,replace_), \"\\n\"+ color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Kilometers_Driven'].fillna(replace_,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few vehicles which have recorded very high values in Kilometers_Driven, we will limit these values to 300000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Kilometers_Driven'].mask(train_data['Kilometers_Driven'] > 300000, 300000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the axes with gridspec\n",
    "x=train_data['vehicle_age']\n",
    "y=train_data['Kilometers_Driven']\n",
    "\n",
    "# Set up the axes with gridspec\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "grid = plt.GridSpec(4, 4, hspace=0.2, wspace=0.2)\n",
    "main_ax = fig.add_subplot(grid[:-1, 1:])\n",
    "y_hist = fig.add_subplot(grid[:-1, 0], xticklabels=[], sharey=main_ax)\n",
    "x_hist = fig.add_subplot(grid[-1, 1:], yticklabels=[], sharex=main_ax)\n",
    "\n",
    "# scatter points on the main axes\n",
    "main_ax.plot(x, y, 'ok', markersize=4, alpha=0.2)\n",
    "\n",
    "# histogram on the attached axes\n",
    "x_hist.hist(x, 40, histtype='stepfilled', orientation='vertical', color='skyblue')\n",
    "#x_hist.invert_yaxis()\n",
    "\n",
    "y_hist.hist(y, 60, histtype='stepfilled', orientation='horizontal', color='skyblue')\n",
    "y_hist.invert_xaxis()\n",
    "\n",
    "# Title \n",
    "plt.suptitle('Relation between Kilometers_Driven and vehicle_age', size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we have addressed the skewness in Kilometers_Driven data, from the above plot we can see that distribution of data is skewed.<br>\n",
    "We will use box-cox transformation to address the skewness and normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Box-Cox Transformation for numeric variables variables  </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Check if the data type of all columns is same in train _data and test_data\n",
    "#train_data.info()\n",
    "#test_data.info()\n",
    "test_data['Kilometers_Driven'] = test_data['Kilometers_Driven'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_traindf = train_data.select_dtypes(include=['int64','float']).drop(columns=['Selling_Price']).apply(lambda x: stats.boxcox(x)[0])\n",
    "numeric_testdf = test_data.select_dtypes(include=['int64','float']).apply(lambda x: stats.boxcox(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace original data with box-cox ransformed data\n",
    "train_data.loc[:, ['Kilometers_Driven', 'Current_Mileage', 'vehicle_age']] = numeric_traindf[['Kilometers_Driven', 'Current_Mileage', 'vehicle_age']]\n",
    "test_data.loc[:, ['Kilometers_Driven', 'Current_Mileage', 'vehicle_age']] = numeric_testdf[['Kilometers_Driven', 'Current_Mileage', 'vehicle_age']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isnull().values.any())\n",
    "print(test_data.isnull().values.any())\n",
    "\n",
    "print(color.BOLD +\"There are no more null values in train_data and test data\"+ color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully imputed all the missing values, normalized the data. This way we can be assured that we have not lost any data.\n",
    "Since the number of missing values is not high we can also choose to delete those rows. But that will lead to loss of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Data Grouping</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group categories within column for category variables. In this method we will check the unique categories within the categorical variables and reduce the number of categories keeping highly appropriate categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cat_column_list={'Transmission': 'Manual transmission is most popular.',\n",
    "                 'Fuel_Type':'Many vehicles that are sold are diesel vehicles, followed by petrol vehicles.',\n",
    "                 'Seller_Type':'Most sellers are indivisual sellers.',\n",
    "                 'Owner_Type':'Many vehicles that are sold are first hand vehicles.',\n",
    "                 'Seats':'5 seater vehicles are owned by majority of the users.',\n",
    "                 'Location':'Popular locaitions where the vehicle is available for purchase are Mumbai, Hyderabad and kochi'}\n",
    "\n",
    "for column in cat_column_list.keys():\n",
    "    #uniques = train_data[column].values\n",
    "    #total_unique=len(list(np.unique(uniques)))\n",
    "    count_uniques = pd.DataFrame(train_data[column].value_counts()).rename(columns={column:'Total_Count'}).sort_values('Total_Count',ascending=False)\n",
    "    \n",
    "    # parameters in format function.\n",
    "    print(color.BOLD +\"Number of unique values in {} is {}\".format(column, count_uniques.shape[0]), \"\\n\"+ color.END)\n",
    "    #print(\"Unique value count in {}\".format(column))\n",
    "    #print(count_uniques)\n",
    "\n",
    "    # Create Figure\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax = sns.barplot(x=count_uniques.index.values.tolist()  , y=\"Total_Count\", data=count_uniques, palette= 'viridis')\n",
    "    # rotates labels and aligns them horizontally to left \n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=90, ha=\"left\" )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"{}\".format(cat_column_list[column]))\n",
    "\n",
    "    print(\"\\n\",'-------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "count_uniques = pd.DataFrame(train_data['Model'].value_counts()).reset_index().rename(columns={'index':'options','Model':'Total_Count'}).sort_values('Total_Count', ascending=False)\n",
    "\n",
    "print(color.BOLD +\"Number of unique values in Model is {}\".format(count_uniques.shape[0]), \"\\n\"+ color.END)\n",
    "\n",
    "dictionary = pd.Series(count_uniques.Total_Count.values,index=count_uniques.options).to_dict()\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=800, background_color='white', colormap='viridis', width=500, height=300, max_words=15).generate_from_frequencies(dictionary)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear') # image show\n",
    "plt.axis('off'); # to off the axis of x and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "count_uniques = pd.DataFrame(train_data['Make'].value_counts()).reset_index().rename(columns={'index':'options','Make':'Total_Count'}).sort_values('Total_Count', ascending=False)\n",
    "\n",
    "print(color.BOLD +\"Number of unique values in Make is {}\".format(count_uniques.shape[0]), \"\\n\"+ color.END)\n",
    "\n",
    "dictionary = pd.Series(count_uniques.Total_Count.values,index=count_uniques.options).to_dict()\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=800, background_color='white', colormap='viridis', width=500, height=300, max_words=15).generate_from_frequencies(dictionary)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear') # image show\n",
    "plt.axis('off'); # to off the axis of x and y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD +\"Aggregate statistics for Selling_price\"+ color.END)\n",
    "train_data['Selling_Price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[train_data.Selling_Price==train_data.Selling_Price.min()]\n",
    "\n",
    "vehicle_ = train_data['Model'][train_data.Selling_Price==train_data.Selling_Price.min()]\n",
    "print(\"One {} vehicle was sold at {} INR, lowest in the dataset\".format(vehicle_.item(), train_data.Selling_Price.min()))\n",
    "vehicle_ = train_data['Model'][train_data.Selling_Price==train_data.Selling_Price.max()]\n",
    "print(\"One {} vehicle was sold at {} INR, highest in the dataset\".format(vehicle_.item(), train_data.Selling_Price.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['Selling_Price'].loc[train_data['Make'] == 'nissan'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "ax = sns.catplot(data=train_data, x='Selling_Price', y='Make',height=10, color='skyblue')  \n",
    "\n",
    "# rotates labels and aligns them horizontally to left \n",
    "plt.suptitle('Selling Price vs Make of Vehicle', size = 15);\n",
    "\n",
    "ax.set(xticks=(2e+05,5e+05,1e+06,2e+06,3e+06,4e+06,5e+06,1e+07))\n",
    "ax.set_xticklabels((2e+05,5e+05,1e+06,2e+06,3e+06,4e+06,5e+06,1e+07), rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selling price of maruti vehicles are between 45000 and 1150000 INR.<br>\n",
    "* Selling price of hyundai vehicles is mostly between 45000 and 1800000 INR but there are some vehicle which were sold for more than 2000000 INR.<br>\n",
    "* Majority of honda vehicles are sold between 90000 and 1200000 INR.<br>\n",
    "* Minimum selling price of nissan vehicles is 175000 and maximum selling price is 892000 INR.<br>\n",
    "* Selling price of maruti vehicles are between 45000 and 1150000 INR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Plot the orbital period with horizontal boxes\n",
    "sns.boxplot(data=train_data, x='Selling_Price', y='Make',\n",
    "            whis=[0, 100], width=.6, color='skyblue')\n",
    "\n",
    "# Add in points to show each observation\n",
    "sns.stripplot(data=train_data, x='Selling_Price', y='Make',\n",
    "              size=4, color=\".3\", linewidth=0)\n",
    "\n",
    "# Tweak the visual presentation\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "sns.despine(trim=True, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selling price of Audi, Mercedes-Benz and BMW vehicles are spread over a wide range.\n",
    "* The median value of Audi, Mercedes-Benz, BMW and Mini brands of vehicles is above 20Lakhs INR.\n",
    "* Median value of Jaguar and Land Rover vehicles is above 30Lakh INR.\n",
    "* 1st Quartile value of Porsche is above 40Lakhs INR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_uniques = pd.DataFrame(train_data['Make'].value_counts()).rename_axis('Make').rename(columns={'Make':'Total_Count'})[24:30]\n",
    "print(tabulate(count_uniques, headers = [\"Make\", \"Total_Count \"], tablefmt=\"pretty\"),'\\n')\n",
    "print(\"There are very few vehicles in our dataset of {}\".format(count_uniques.index.tolist()))\n",
    "vehicle_ = train_data.loc[train_data['Make'] == 'bentley']\n",
    "print(\"There is only one {} vehicle was sold at {} INR\".format(vehicle_.Model.item(), vehicle_.Selling_Price.item()))\n",
    "vehicle_ = train_data.loc[train_data['Make'] == 'ambassador']\n",
    "print(\"There is only one {} vehicle was sold at {} INR\".format(vehicle_.Model.item(), vehicle_.Selling_Price.item()))\n",
    "vehicle_ = train_data.loc[train_data['Make'] == 'smart']\n",
    "print(\"There is only one {} vehicle was sold at {} INR\".format(vehicle_.Model.item(), vehicle_.Selling_Price.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> categorical variables into Binary variables and adding new columns </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If vehicle is in top 15 in Make, encode the column value as 1 else 0 in Make_15_BIN\n",
    "* If vehicle is in top 15 in Model, encode the column value as 1 else 0 in Model_15_BIN\n",
    "* If Location is in list of metero cities ['Chennai','Delhi','Mumbai','Kolkata','Ahmedabad','Bangalore','Hyderabad','Pune'], encode the column value as 1 else 0 in Model_15_BIN\n",
    "* If Fuel_Type is other than Petrol or Diesel, change it to 'Gas_fuel'\n",
    "* If Owner_Type is other than First or Second, change it to 'Third&above'\n",
    "* If Seats are other than 2,4,5, change to '6nabove'\n",
    "* If Seller_Type other than 'Individual' change to 'Dealer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the categorical variables into Binary variable\n",
    "\n",
    "fuel_list= ['Diesel','Petrol']\n",
    "Owner_Type= ['First','Second']\n",
    "Seats= [2,4,5]\n",
    "Seller_Type= ['Individual']\n",
    "Make_top15_list= train_data.Make.value_counts().index[0:15].to_list()\n",
    "Model_top15_list= train_data.Model.value_counts().index[0:15].to_list()\n",
    "Metro_city_list= ['Chennai','Delhi','Mumbai','Kolkata','Ahmedabad','Bangalore','Hyderabad','Pune']\n",
    "\n",
    "def Binary_variable(df):\n",
    "    df['Fuel_Type'] = df['Fuel_Type'].apply(lambda x: x if x in fuel_list else 'Gas_fuel')\n",
    "    df['Owner_Type'] = df['Owner_Type'].apply(lambda x: x if x in Owner_Type else 'Third&above')\n",
    "    df['Seats'] = df['Seats'].apply(lambda x: x if x in Seats else '6nabove')\n",
    "    df['Seller_Type'] = df['Seller_Type'].apply(lambda x: x if x in Seller_Type else 'Dealer')\n",
    "    df['Make_15_BIN'] = df['Make'].apply(lambda x: 1 if x in Make_top15_list else 0)#.astype('category')\n",
    "    df['Model_15_BIN'] = df['Model'].apply(lambda x: 1 if x in Model_top15_list else 0)#.astype('category')\n",
    "    df['Location'] = df['Location'].apply(lambda x: 1 if x in Metro_city_list else 0)\n",
    "\n",
    "\n",
    "Binary_variable(train_data)\n",
    "Binary_variable(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Make and Model columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column_list=['Make', 'Model']\n",
    "train_data.drop(drop_column_list, axis=1, inplace=True)\n",
    "test_data.drop(drop_column_list, axis=1, inplace=True)\n",
    "#train_data.info()\n",
    "#test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Dummy Variable Creation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary values using get_dummies\n",
    "train_df = pd.get_dummies(train_data)\n",
    "test_df = pd.get_dummies(test_data)\n",
    "#train_df.shape\n",
    "#test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Correlation matrix </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat=train_df.corr()\n",
    "top_corr_features=corrmat.index\n",
    "plt.figure(figsize=(25,25))\n",
    "#plot heat map\n",
    "g=sns.heatmap(train_df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can delete columns which have high correlation with other columns.<br>Fuel_Type_Diesel-Fuel_Type_Petrol,<br> Transmission_Automatic-Transmission_Manual,<br> Seller_Type_Dealer-Seller_Type_Individual, <br>Owner_Type_Second-Owner_Type_First,<br> Seats_6nabove-Seats5.0 <br> have high correlation with each other. <br>Hence we can drop\n",
    "'Fuel_Type_Diesel', 'Transmission_Automatic','Seller_Type_Dealer', 'Owner_Type_Second', 'Seats_6nabove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column_list=['Fuel_Type_Diesel', 'Transmission_Automatic','Seller_Type_Dealer', 'Owner_Type_Second', 'Seats_6nabove']\n",
    "\n",
    "train_df.drop(columns=[col for col in train_df if col in drop_column_list], inplace=True)\n",
    "test_df.drop(columns=[col for col in test_df if col in drop_column_list], inplace=True)\n",
    "\n",
    "#train_df.drop(drop_column_list, axis=1, inplace=True)\n",
    "#test_df.drop(drop_column_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.columns\n",
    "#test_df.columns\n",
    "#train_df[train_df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "#test_df[test_df.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_csv(\"train_df_check.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Feature Importance </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With feature importance we can understand which features are very important for price prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,1:]  #independent columns\n",
    "y = train_df.iloc[:,0]    #target column Selling_Price\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X,y)\n",
    "\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feature_importances.nlargest(15).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transmission type is the very important feature followed by vehicle age\n",
    "* Current Mileage and Kilometers Driven are almost equally important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following are the top 15 features(columns) in the order of decreasing importance that govern the selling pricec of the vehicle.\",'\\n')\n",
    "print(feature_importances.nlargest(15).index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Blue'> Model Building  </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df.drop(columns='Selling_Price', axis=1)\n",
    "y=train_df['Selling_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Maroon'> Random Forest Regressor </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a random forest regressor model.<br>\n",
    "We will also use RandomizedSearchCV.<br> \n",
    "* In RandomizedSearchCV not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg=RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = rfreg, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=123, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a hyperparameter optimization is a single set of well-performing hyperparameters that you can use to configure your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters finalized for random forest regressor\")\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <span style='color:Maroon'> Make predictions on holdout sample </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_predicted)) \n",
    "print('Mean Absolute Percentage Error:',mean_absolute_percentage_error(y_test,y_predicted))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_predicted))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_predicted)))\n",
    "print('R2 score: ', r2_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "plt.scatter(y_test, y_predicted)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Actual vs Predicted Price\")\n",
    "ax.set(xticks=(2e+05,5e+05,1e+06,2e+06,3e+06,4e+06,5e+06,1e+07))\n",
    "ax.set_xticklabels((2e+05,5e+05,1e+06,2e+06,3e+06,4e+06,5e+06,1e+07), rotation=90)\n",
    "ax.set(yticks=(2e+05,5e+05,1e+06,2e+06,3e+06,4e+06,5e+06,1e+07))\n",
    "ax.set_yticklabels((2e+05,5e+05,1e+06,2e+06,3e+06,4e+06,5e+06,1e+07))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Blue'> Make Predictions on Test Data </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=rf_random.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=pd.DataFrame(y_predicted, index =list(test_df.index)).rename(columns={0:'Predicted_Selling_Price'})\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
